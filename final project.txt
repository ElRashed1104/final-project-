import matplotlib.pyplot as plt

import numpy as np 


import pandas as ps 

import sklearn

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

data = ps.read_csv('/content/car_price_dataset.csv')

print(data.head())
print(data.describe())
# Check for missing values
print(data.isnull().sum())
# Dropping rows with missing values (or you could fill them)
data = data.dropna()



plt.figure(figsize=(10, 6))
#sns.histplot(data['your_numerical_column'], bins=30, kde=True)
plt.title('Distribution of Your Numerical Column')
plt.xlabel('Engine_Size')
plt.ylabel('Mileage')
plt.show()

import seaborn as sns

X = data.drop('Engine_Size', axis=1)  # Features
y = data['Year']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Visualize the distribution of car prices
plt.figure(figsize=(10, 6))
sns.histplot(data['Mileage'], bins=30, kde=True)
plt.title('Distribution of Car Prices')
plt.xlabel('Car Price')
plt.ylabel('Frequency')
plt.show()



# Create an instance of the Linear Regression model
model = LinearRegression()

# Train the model using the training data
model.fit(X_train , y_train)

# Assuming model has been trained and X_test is available
y_pred = model.predict(X_test)

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_pred)

# Calculate R-Squared
r_squared = r2_score(y_test, y_pred)
# Print the results
print(f'Mean Squared Error (MSE): {mse}')
print(f'R-Squared (RÂ²): {r_squared}')

# Print coefficients
coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])
print(coefficients)
